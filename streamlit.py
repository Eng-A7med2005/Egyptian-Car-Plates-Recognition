import gdown
import streamlit as st
import cv2
import torch
import numpy as np
from ultralytics import YOLO

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø£ÙˆÙ„: Ù„Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ÙˆØ­Ø§Øª
plate_model_url = 'https://drive.google.com/uc?id=12tRfc_-nOkqMO9bdwpV8P8MFamwgtR2e'
plate_model_file = 'yolo11m_car_plate_ocr.pt'
gdown.download(plate_model_url, plate_model_file, quiet=False)
plate_detector = YOLO(plate_model_file)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø«Ø§Ù†ÙŠ: Ù„Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù„ÙˆØ­Ø©
ocr_model_file = 'yolo11m_car_plate_ocr1.pt'
ocr_model = YOLO(ocr_model_file)

# ÙˆØ§Ø¬Ù‡Ø© Streamlit
st.title("ğŸš˜ Car Plate Recognition Using Dual YOLO Models")

uploaded_image = st.file_uploader("Upload a Car Image", type=["jpg", "jpeg", "png"])

if uploaded_image is not None:
    file_bytes = np.frombuffer(uploaded_image.read(), np.uint8)
    image = cv2.imdecode(file_bytes, cv2.IMREAD_COLOR)
    rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

    st.image(rgb_image, caption="Uploaded Image", use_column_width=True)

    # ---- Ø§Ù„Ø®Ø·ÙˆØ© 1: Ø§ÙƒØªØ´Ø§Ù Ø§Ù„Ù„ÙˆØ­Ø§Øª ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© ----
    plate_results = plate_detector.predict(rgb_image, conf=0.3)

    if len(plate_results[0].boxes) == 0:
        st.warning("No plates were detected.")
    else:
        st.subheader("Detected Plates and Their Content:")
        for i, box in enumerate(plate_results[0].boxes):
            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())
            plate_crop = rgb_image[y1:y2, x1:x2]

            # ---- Ø§Ù„Ø®Ø·ÙˆØ© 2: Ù‚Ø±Ø§Ø¡Ø© Ù…Ø­ØªÙˆÙ‰ Ø§Ù„Ù„ÙˆØ­Ø© Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù†Ù…ÙˆØ°Ø¬ Ø§Ù„Ø«Ø§Ù†ÙŠ ----
            ocr_results = ocr_model.predict(plate_crop, conf=0.25)

            # Ø±Ø³Ù… Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ù…Ø±Ø¨Ø¹Ø§Øª
            plotted = ocr_results[0].plot()

            # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø­Ø±ÙˆÙ ÙˆØ§Ù„Ø£Ø±Ù‚Ø§Ù… Ø­Ø³Ø¨ ØªØ±ØªÙŠØ¨Ù‡Ù… Ù…Ù† Ø§Ù„ÙŠØ³Ø§Ø± Ù„Ù„ÙŠÙ…ÙŠÙ†
            detected_items = []
            for char_box in ocr_results[0].boxes:
                class_id = int(char_box.cls[0])
                name = ocr_results[0].names[class_id]
                x_center = (char_box.xyxy[0][0] + char_box.xyxy[0][2]) / 2
                detected_items.append((x_center, name))

            # ØªØ±ØªÙŠØ¨ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø­Ø³Ø¨ X
            detected_items.sort(key=lambda x: x[0])
            plate_text = ''.join([item[1] for item in detected_items])

            # ---- Ø§Ù„Ø¹Ø±Ø¶ ----
            st.image(plate_crop, caption=f"Plate Region #{i+1}", use_column_width=True)
            st.image(plotted, caption=f"Characters Detected in Plate #{i+1}", use_column_width=True)
            st.success(f"ğŸ”  Recognized Text: **{plate_text}**")

    # Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø¹Ø§Ù…Ø© Ù…Ø¹ Ø§Ù„Ù„ÙˆØ­Ø§Øª
    img_with_boxes = plate_results[0].plot()
    st.image(img_with_boxes, caption="Image with Detected Plates", use_column_width=True)
